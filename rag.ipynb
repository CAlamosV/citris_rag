{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (0.27.2)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from openai) (2.29.0)\n",
      "Requirement already satisfied: tqdm in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (20.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.7.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/calamos/opt/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'OpenAI' from 'openai' (/Users/calamos/opt/anaconda3/lib/python3.8/site-packages/openai/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m OpenAI, AssistantEventHandler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping_extensions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m override\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the OpenAI client\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'OpenAI' from 'openai' (/Users/calamos/opt/anaconda3/lib/python3.8/site-packages/openai/__init__.py)"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI, AssistantEventHandler\n",
    "from typing_extensions import override\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create a new Assistant with File Search Enabled\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Document Query Assistant\",\n",
    "    instructions=\"You are a helpful assistant. Use your knowledge base to answer questions about the uploaded documents.\",\n",
    "    model=\"gpt-4o\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    ")\n",
    "\n",
    "# Step 2: Upload files and add them to a Vector Store\n",
    "vector_store = client.beta.vector_stores.create(name=\"Document Storage\")\n",
    "file_paths = [\"path/to/your/file1.txt\", \"path/to/your/file2.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# Step 3: Update the assistant to use the new Vector Store\n",
    "assistant = client.beta.assistants.update(\n",
    "    assistant_id=assistant.id,\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")\n",
    "\n",
    "# Step 4: Create a thread and attach files\n",
    "message_file = client.files.create(\n",
    "    file=open(\"path/to/your/file3.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \n",
    "            \"content\": \"Ask your question here.\",\n",
    "            \"attachments\": [\n",
    "                {\"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}]}\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Step 5: Create a run and check the output\n",
    "class EventHandler(AssistantEventHandler):\n",
    "    @override\n",
    "    def on_text_created(self, text) -> None:\n",
    "        print(f\"\\nassistant > {text}\", end=\"\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_tool_call_created(self, tool_call):\n",
    "        print(f\"\\nassistant > {tool_call.type}\\n\", flush=True)\n",
    "\n",
    "    @override\n",
    "    def on_message_done(self, message) -> None:\n",
    "        message_content = message.content[0].text\n",
    "        annotations = message_content.annotations\n",
    "        citations = []\n",
    "        for index, annotation in enumerate(annotations):\n",
    "            message_content.value = message_content.value.replace(\n",
    "                annotation.text, f\"[{index}]\"\n",
    "            )\n",
    "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "                cited_file = client.files.retrieve(file_citation.file_id)\n",
    "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "        print(message_content.value)\n",
    "        print(\"\\n\".join(citations))\n",
    "\n",
    "with client.beta.threads.runs.stream(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant.id,\n",
    "    instructions=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    "    event_handler=EventHandler(),\n",
    ") as stream:\n",
    "    stream.until_done()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
